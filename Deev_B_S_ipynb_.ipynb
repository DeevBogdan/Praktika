{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nZLr42LQeZNj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "outputId": "9d7e88ec-3d0e-4827-e914-ee73d92ef9ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-9-3645203907.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Загрузка модели (выполняется один раз при старте)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Загружаем модель...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobileNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Модель готова к работе!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/mobilenet_v2.py\u001b[0m in \u001b[0;36mMobileNetV2\u001b[0;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 283\u001b[0;31m     x = _inverted_res_block(\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpansion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/applications/mobilenet_v2.py\u001b[0m in \u001b[0;36m_inverted_res_block\u001b[0;34m(inputs, expansion, stride, alpha, filters, block_id)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Project with a pointwise 1x1 convolution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     x = layers.Conv2D(\n\u001b[0m\u001b[1;32m    458\u001b[0m         \u001b[0mpointwise_filters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/conv2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     ):\n\u001b[0;32m--> 109\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1447\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_tracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trackable.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_self_setattr_tracking\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             value = sticky_attribute_assignment(\n\u001b[1;32m     26\u001b[0m                 \u001b[0mtrackable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi nest-asyncio uvicorn python-multipart tensorflow pillow -q\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import logging\n",
        "from google.colab.output import eval_js\n",
        "import threading\n",
        "\n",
        "# Настройка логгирования\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Загрузка модели\n",
        "logger.info(\"Загружаем модель...\")\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "logger.info(\"Модель готова к работе!\")\n",
        "\n",
        "# Создание FastAPI приложения\n",
        "app = FastAPI(title=\"Object Recognition API\")\n",
        "\n",
        "# Настройка CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "async def process_image(file_bytes):\n",
        "    try:\n",
        "        img = Image.open(io.BytesIO(file_bytes))\n",
        "        if img.format not in ['JPEG', 'PNG', 'JPG']:\n",
        "            raise HTTPException(status_code=400, detail=\"Поддерживаются только JPEG/PNG\")\n",
        "        if len(file_bytes) > 5 * 1024 * 1024:\n",
        "            raise HTTPException(status_code=400, detail=\"Слишком большой файл (макс. 5MB)\")\n",
        "\n",
        "        img = img.resize((224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "\n",
        "        predictions = model.predict(img_array)\n",
        "        results = decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "        return [\n",
        "            {\"object\": result[1], \"confidence\": float(result[2])}\n",
        "            for result in results\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка обработки: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    results = await process_image(contents)\n",
        "    return {\"predictions\": results, \"top_prediction\": results[0]}\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def test_interface():\n",
        "    return \"\"\"\n",
        "    <h1>Сервис распознавания объектов</h1>\n",
        "    <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "        <input type=\"file\" name=\"file\" accept=\"image/*\">\n",
        "        <button type=\"submit\">Распознать</button>\n",
        "    </form>\n",
        "    \"\"\"\n",
        "\n",
        "def start_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "    threading.Thread(target=start_server, daemon=True).start()\n",
        "    public_url = eval_js(\"google.colab.kernel.proxyPort(8000)\")\n",
        "    print(f\"API доступен по адресу: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "5NbpMPvTMrXL",
        "outputId": "eeccb79f-d309-4e6e-af4c-25ae6cb15e50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-10' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:69> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 70, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 331, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n",
            "INFO:     Started server process [700]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API доступен по адресу: https://8000-m-s-3bs3on7d34kd-a.asia-east1-1.prod.colab.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка зависимостей\n",
        "!pip install fastapi uvicorn python-multipart tensorflow pillow nest-asyncio pydantic -q\n",
        "\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.responses import JSONResponse\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import logging\n",
        "import nest_asyncio\n",
        "from google.colab.output import eval_js\n",
        "import threading\n",
        "\n",
        "# Настройка логгирования\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Инициализация модели\n",
        "logger.info(\"Инициализация модели MobileNetV2...\")\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "logger.info(\"Модель успешно загружена\")\n",
        "\n",
        "# Создание FastAPI приложения\n",
        "app = FastAPI(title=\"Object Recognition API\")\n",
        "\n",
        "# Включение CORS\n",
        "app.add_middleware(\n",
        "    \"fastapi.middleware.CORSMiddleware\",\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Модели Pydantic для ответа API\n",
        "class PredictionResult(BaseModel):\n",
        "    object: str\n",
        "    confidence: float\n",
        "\n",
        "class APIResponse(BaseModel):\n",
        "    success: bool\n",
        "    predictions: List[PredictionResult]\n",
        "    top_prediction: PredictionResult\n",
        "    error: Optional[str] = None\n",
        "\n",
        "def process_image_file(file: UploadFile) -> np.ndarray:\n",
        "    \"\"\"Обработка загруженного файла изображения\"\"\"\n",
        "    try:\n",
        "        contents = file.file.read()\n",
        "        if len(contents) > 5 * 1024 * 1024:\n",
        "            raise HTTPException(status_code=400, detail=\"Файл слишком большой (макс. 5MB)\")\n",
        "\n",
        "        img = Image.open(io.BytesIO(contents))\n",
        "        if img.format not in ['JPEG', 'PNG', 'JPG']:\n",
        "            raise HTTPException(status_code=400, detail=\"Неподдерживаемый формат изображения\")\n",
        "\n",
        "        img = img.resize((224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        return preprocess_input(img_array)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Ошибка обработки файла: {str(e)}\")\n",
        "        raise HTTPException(status_code=400, detail=f\"Ошибка обработки изображения: {str(e)}\")\n",
        "\n",
        "@app.post(\"/predict\", response_model=APIResponse)\n",
        "async def predict_object(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        processed_image = process_image_file(file)\n",
        "        predictions = model.predict(processed_image)\n",
        "        decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "        results = [\n",
        "            PredictionResult(object=label, confidence=float(conf))\n",
        "            for (_, label, conf) in decoded_predictions\n",
        "        ]\n",
        "\n",
        "        return APIResponse(\n",
        "            success=True,\n",
        "            predictions=results,\n",
        "            top_prediction=results[0]\n",
        "        )\n",
        "\n",
        "    except HTTPException as he:\n",
        "        return JSONResponse(\n",
        "            content={\n",
        "                \"success\": False,\n",
        "                \"error\": he.detail,\n",
        "                \"predictions\": [],\n",
        "                \"top_prediction\": None\n",
        "            },\n",
        "            status_code=he.status_code\n",
        "        )\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Неожиданная ошибка: {str(e)}\")\n",
        "        return JSONResponse(\n",
        "            content={\n",
        "                \"success\": False,\n",
        "                \"error\": \"Внутренняя ошибка сервера\",\n",
        "                \"predictions\": [],\n",
        "                \"top_prediction\": None\n",
        "            },\n",
        "            status_code=500\n",
        "        )\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def test_interface():\n",
        "    return \"\"\"\n",
        "    <html>\n",
        "    <body>\n",
        "        <h1>Сервис распознавания объектов</h1>\n",
        "        <form action=\"/predict\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "            <input type=\"file\" name=\"file\" accept=\"image/*\" required>\n",
        "            <button type=\"submit\">Распознать объекты</button>\n",
        "        </form>\n",
        "        <div id=\"result\" style=\"margin-top:20px;\"></div>\n",
        "        <script>\n",
        "            document.querySelector('form').addEventListener('submit', async (e) => {\n",
        "                e.preventDefault();\n",
        "                const formData = new FormData(e.target);\n",
        "                const response = await fetch('/predict', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "                const result = await response.json();\n",
        "                document.getElementById('result').innerHTML = `\n",
        "                    <h3>Результаты:</h3>\n",
        "                    <p>Наиболее вероятный объект: <strong>${result.top_prediction.object}</strong></p>\n",
        "                    <p>Уверенность: <strong>${(result.top_prediction.confidence * 100).toFixed(2)}%</strong></p>\n",
        "                    <h4>Все варианты:</h4>\n",
        "                    <ul>\n",
        "                        ${result.predictions.map(p => `<li>${p.object} (${(p.confidence * 100).toFixed(2)}%)</li>`).join('')}\n",
        "                    </ul>\n",
        "                `;\n",
        "            });\n",
        "        </script>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "    server_thread.start()\n",
        "\n",
        "    public_url = eval_js(\"google.colab.kernel.proxyPort(8000)\")\n",
        "    print(f\"Сервис доступен по адресу: {public_url}\")\n",
        "    print(\"Отправляйте POST-запросы с изображениями на /predict\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "qdBKRo30Sb9a",
        "outputId": "0e2ce70f-29e8-42e2-9e25-0fbf63c007d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [700]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     ASGI 'lifespan' protocol appears unsupported.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): address already in use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сервис доступен по адресу: https://8000-m-s-3bs3on7d34kd-a.asia-east1-1.prod.colab.dev\n",
            "Отправляйте POST-запросы с изображениями на /predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"success\": True,\n",
        "  \"predictions\": [\n",
        "    {\"object\": \"labrador\", \"confidence\": 0.95},\n",
        "    {\"object\": \"retriever\", \"confidence\": 0.03}\n",
        "  ],\n",
        "  \"top_prediction\": {\"object\": \"labrador\", \"confidence\": 0.95}\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuqJN5k5SuUp",
        "outputId": "2b154d7d-7e47-4dee-d43b-7b8f5850b1d8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'predictions': [{'object': 'labrador', 'confidence': 0.95},\n",
              "  {'object': 'retriever', 'confidence': 0.03}],\n",
              " 'top_prediction': {'object': 'labrador', 'confidence': 0.95}}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Установка Docker в Colab\n",
        "!curl -fsSL https://get.docker.com -o get-docker.sh\n",
        "!sh get-docker.sh\n",
        "\n",
        "# 2. Создаем файл requirements.txt правильно\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write(\"\"\"fastapi==0.68.1\n",
        "uvicorn==0.15.0\n",
        "python-multipart==0.0.5\n",
        "tensorflow==2.6.0\n",
        "pillow==8.3.2\n",
        "\"\"\")\n",
        "\n",
        "# 3. Создаем основной файл приложения\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"from fastapi import FastAPI, UploadFile, File, HTTPException\n",
        "from fastapi.responses import JSONResponse\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import uvicorn\n",
        "\n",
        "app = FastAPI()\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        img = Image.open(io.BytesIO(await file.read()))\n",
        "        img = img.resize((224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "\n",
        "        preds = model.predict(img_array)\n",
        "        results = decode_predictions(preds, top=3)[0]\n",
        "\n",
        "        return JSONResponse(content={\n",
        "            \"success\": True,\n",
        "            \"predictions\": [{\"label\": label, \"confidence\": float(conf)}\n",
        "                          for (_, label, conf) in results]\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return JSONResponse(\n",
        "            content={\"success\": False, \"error\": str(e)},\n",
        "            status_code=400\n",
        "        )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\"\"\")\n",
        "\n",
        "# 4. Создаем Dockerfile\n",
        "with open('Dockerfile', 'w') as f:\n",
        "    f.write(\"\"\"FROM python:3.9-slim\n",
        "WORKDIR /app\n",
        "COPY . .\n",
        "RUN apt-get update && \\\\\n",
        "    apt-get install -y --no-install-recommends gcc python3-dev && \\\\\n",
        "    pip install --no-cache-dir -r requirements.txt && \\\\\n",
        "    apt-get remove -y gcc python3-dev && \\\\\n",
        "    apt-get autoremove -y && \\\\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "EXPOSE 8000\n",
        "CMD [\"python\", \"app.py\"]\n",
        "\"\"\")\n",
        "\n",
        "# 5. Собираем и запускаем контейнер\n",
        "!docker build -t colab-app .\n",
        "!docker run -d -p 8000:8000 --name my-app colab-app\n",
        "\n",
        "# 6. Проверяем работу\n",
        "import time\n",
        "time.sleep(5)\n",
        "print(\"Сервис доступен по адресу: http://localhost:8000\")\n",
        "print(\"Пример тестового запроса:\")\n",
        "print(\"\"\"\n",
        "import requests\n",
        "url = \"http://localhost:8000/predict\"\n",
        "files = {'file': open('test.jpg', 'rb')}\n",
        "response = requests.post(url, files=files)\n",
        "print(response.json())\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ofvsJhqVztR",
        "outputId": "af69151d-b455-4188-ea19-ce04a519532d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Executing docker install script, commit: 7040dd2bf115a359317b1de84de611aeabcb7bc2\n",
            "+ sh -c apt-get -qq update >/dev/null\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "+ sh -c DEBIAN_FRONTEND=noninteractive apt-get -y -qq install ca-certificates curl >/dev/null\n",
            "+ sh -c install -m 0755 -d /etc/apt/keyrings\n",
            "+ sh -c curl -fsSL \"https://download.docker.com/linux/ubuntu/gpg\" -o /etc/apt/keyrings/docker.asc\n",
            "+ sh -c chmod a+r /etc/apt/keyrings/docker.asc\n",
            "+ sh -c echo \"deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu jammy stable\" > /etc/apt/sources.list.d/docker.list\n",
            "+ sh -c apt-get -qq update >/dev/null\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "+ sh -c DEBIAN_FRONTEND=noninteractive apt-get -y -qq install docker-ce docker-ce-cli containerd.io docker-compose-plugin docker-ce-rootless-extras docker-buildx-plugin docker-model-plugin >/dev/null\n",
            "\n",
            "================================================================================\n",
            "\n",
            "To run Docker as a non-privileged user, consider setting up the\n",
            "Docker daemon in rootless mode for your user:\n",
            "\n",
            "    dockerd-rootless-setuptool.sh install\n",
            "\n",
            "Visit https://docs.docker.com/go/rootless/ to learn about rootless mode.\n",
            "\n",
            "\n",
            "To run the Docker daemon as a fully privileged service, but granting non-root\n",
            "users access, refer to https://docs.docker.com/go/daemon-access/\n",
            "\n",
            "WARNING: Access to the remote API on a privileged Docker daemon is equivalent\n",
            "         to root access on the host. Refer to the 'Docker daemon attack surface'\n",
            "         documentation for details: https://docs.docker.com/go/attack-surface/\n",
            "\n",
            "================================================================================\n",
            "\n",
            "ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
            "\n",
            "Run 'docker run --help' for more information\n",
            "Сервис доступен по адресу: http://localhost:8000\n",
            "Пример тестового запроса:\n",
            "\n",
            "import requests\n",
            "url = \"http://localhost:8000/predict\"\n",
            "files = {'file': open('test.jpg', 'rb')}\n",
            "response = requests.post(url, files=files)\n",
            "print(response.json())\n",
            "\n"
          ]
        }
      ]
    }
  ]
}